# Guide de D√©ploiement - SNCF Travel Assistant

Ce guide d√©taille les √©tapes compl√®tes pour d√©ployer l'application sur Databricks Apps.

## üìã Pr√©requis

### 1. Outils Requis

- **Databricks CLI** (version 0.210.0+)
- **Python 3.10+**
- **Git**
- **npm/pnpm** (pour le build du frontend si n√©cessaire)

### 2. Permissions Databricks

Vous devez avoir les permissions suivantes dans le workspace :
- Cr√©er et g√©rer des Apps
- Cr√©er des Model Serving Endpoints
- Acc√®s en lecture/√©criture au Unity Catalog (si utilis√©)
- G√©rer des Secrets

## üîß Configuration Initiale

### √âtape 1 : Installation de Databricks CLI

```bash
# Avec pip
pip install databricks-cli

# Avec Homebrew (macOS)
brew install databricks

# V√©rifier l'installation
databricks --version
```

### √âtape 2 : Configuration du CLI

```bash
databricks configure --token
```

Vous serez invit√© √† fournir :
- **Host** : URL de votre workspace (ex: https://your-workspace.cloud.databricks.com)
- **Token** : Votre token d'acc√®s personnel (√† g√©n√©rer depuis le workspace)

Pour g√©n√©rer un token :
1. Connectez-vous √† votre workspace Databricks
2. Allez dans **Settings** ‚Üí **User Settings** ‚Üí **Access Tokens**
3. Cliquez sur **Generate New Token**
4. Copiez le token (il ne sera affich√© qu'une fois !)

### √âtape 3 : V√©rification de la Configuration

```bash
# Tester la connexion
databricks workspace list /

# V√©rifier votre identit√©
databricks current-user me
```

## üèóÔ∏è Configuration du Projet

### √âtape 1 : Mise √† Jour de databricks.yml

Ouvrez `databricks.yml` et remplacez les valeurs suivantes :

```yaml
targets:
  dev:
    workspace:
      host: https://votre-workspace.cloud.databricks.com  # REMPLACER ICI
```

Pour chaque environnement (dev, staging, prod), mettez √† jour le `host`.

### √âtape 2 : Configuration des Variables du Catalog

Dans `databricks.yml`, section `variables` :

```yaml
variables:
  catalog:
    default: "votre_catalog"  # REMPLACER ICI
  
  schema:
    default: "votre_schema"   # REMPLACER ICI
```

### √âtape 3 : Configuration de l'Endpoint Agent AI

Dans `app.yaml` et `databricks.yml`, mettez √† jour l'URL de l'endpoint :

```yaml
env:
  - name: AGENT_ENDPOINT_URL
    value: "https://votre-workspace/serving-endpoints/votre-endpoint/invocations"
```

## üîê Configuration des Secrets

### Cr√©er le Scope de Secrets

```bash
# Cr√©er un nouveau scope
databricks secrets create-scope sncf-travel-app

# V√©rifier qu'il a √©t√© cr√©√©
databricks secrets list-scopes
```

### Ajouter les Secrets

```bash
# Token pour l'authentification (utiliser un Service Principal en production)
databricks secrets put-secret sncf-travel-app databricks-token

# Un √©diteur de texte s'ouvrira, collez votre token, sauvegardez et fermez
```

### V√©rifier les Secrets

```bash
# Lister les secrets (les valeurs ne sont pas affich√©es)
databricks secrets list-secrets sncf-travel-app
```

## üö¢ D√©ploiement

### Validation Avant D√©ploiement

```bash
# Valider la syntaxe et la configuration
databricks bundle validate -t dev

# Si des erreurs apparaissent, corrigez-les avant de continuer
```

Erreurs courantes :
- `workspace.host not set` ‚Üí Mettez √† jour le host dans databricks.yml
- `invalid resource configuration` ‚Üí V√©rifiez la syntaxe YAML

### Premier D√©ploiement (Dev)

```bash
# D√©ployer sur l'environnement de d√©veloppement
databricks bundle deploy -t dev

# Cette commande va :
# 1. Uploader le code source vers le workspace
# 2. Cr√©er l'app
# 3. Cr√©er le model serving endpoint (si configur√©)
# 4. Cr√©er les jobs (si configur√©s)
```

### V√©rifier le D√©ploiement

```bash
# Lister les apps d√©ploy√©es
databricks apps list

# Obtenir les d√©tails de l'app
databricks apps get sncf-travel-assistant-dev

# La commande affichera notamment l'URL de l'app
```

### Acc√©der √† l'Application

1. **Via CLI** :
   ```bash
   # Obtenir l'URL
   databricks apps get sncf-travel-assistant-dev --output json | grep '"url"'
   ```

2. **Via Console Web** :
   - Connectez-vous au workspace Databricks
   - Allez dans **Apps** (dans le menu de gauche)
   - Cliquez sur votre app

### Consulter les Logs

```bash
# Logs en temps r√©el
databricks apps logs sncf-travel-assistant-dev --follow

# Logs des derni√®res heures
databricks apps logs sncf-travel-assistant-dev --since 2h

# Sauvegarder les logs dans un fichier
databricks apps logs sncf-travel-assistant-dev > app.log
```

## üîÑ D√©ploiement Staging et Production

### Staging

```bash
# 1. Valider la config staging
databricks bundle validate -t staging

# 2. D√©ployer
databricks bundle deploy -t staging

# 3. V√©rifier
databricks apps get sncf-travel-assistant-staging
```

### Production

‚ö†Ô∏è **IMPORTANT** : En production, utilisez un Service Principal au lieu de votre token personnel.

#### Cr√©er un Service Principal

1. Dans le workspace Databricks, allez dans **Admin Console**
2. Cliquez sur **Service Principals**
3. **Add Service Principal**
4. Notez l'Application ID
5. G√©n√©rez un secret client

#### Configurer le CLI pour le Service Principal

```bash
# Cr√©er un nouveau profil pour la production
databricks configure --token --profile production

# Utiliser le token du service principal
```

#### D√©ployer en Production

```bash
# 1. Valider
databricks bundle validate -t prod --profile production

# 2. D√©ployer
databricks bundle deploy -t prod --profile production

# 3. V√©rifier
databricks apps get sncf-travel-assistant --profile production
```

## üß™ Tests Post-D√©ploiement

### Test de Sant√©

```bash
# Tester l'endpoint health
curl https://votre-app-url/health

# R√©ponse attendue :
# {
#   "status": "healthy",
#   "timestamp": "2026-01-21T...",
#   "agent_configured": true
# }
```

### Test du Chatbot

```bash
# Test du endpoint chat
curl -X POST https://votre-app-url/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Quel est mon prochain train ?",
    "user_id": "test-user"
  }'
```

### Test du Dashboard Admin

```bash
# Test des KPIs
curl https://votre-app-url/api/admin/kpis

# Test des charts
curl https://votre-app-url/api/admin/charts
```

## üîÑ Mises √† Jour

### Mettre √† Jour le Code

```bash
# 1. Modifier le code localement
# 2. Commit (optionnel mais recommand√©)
git add .
git commit -m "Update: description"

# 3. Red√©ployer
databricks bundle deploy -t dev

# L'app red√©marre automatiquement avec le nouveau code
```

### Mettre √† Jour la Configuration

```bash
# 1. Modifier app.yaml ou databricks.yml
# 2. Valider
databricks bundle validate -t dev

# 3. Red√©ployer
databricks bundle deploy -t dev
```

### Mettre √† Jour les Secrets

```bash
# Mettre √† jour un secret existant
databricks secrets put-secret sncf-travel-app databricks-token

# Red√©marrer l'app pour prendre en compte le nouveau secret
databricks apps restart sncf-travel-assistant-dev
```

## üõ†Ô∏è Gestion de l'Application

### Commandes Utiles

```bash
# Lister toutes les apps
databricks apps list

# D√©marrer une app arr√™t√©e
databricks apps start sncf-travel-assistant-dev

# Arr√™ter une app
databricks apps stop sncf-travel-assistant-dev

# Red√©marrer une app
databricks apps restart sncf-travel-assistant-dev

# Supprimer une app
databricks apps delete sncf-travel-assistant-dev

# Obtenir les m√©triques
databricks apps get-metrics sncf-travel-assistant-dev
```

### Monitoring

Dans la console Databricks Apps, vous pouvez voir :
- **Status** : Running, Stopped, Error
- **M√©triques** : CPU, RAM, requ√™tes/sec
- **Logs** : Logs en temps r√©el
- **Events** : Historique des √©v√©nements (d√©marrage, erreurs, etc.)

## üêõ Troubleshooting

### Probl√®me : "App failed to start"

```bash
# 1. Consulter les logs
databricks apps logs sncf-travel-assistant-dev

# 2. V√©rifier les erreurs courantes :
# - D√©pendances manquantes (requirements.txt)
# - Variables d'environnement incorrectes
# - Port d√©j√† utilis√©
# - Erreur dans le code
```

### Probl√®me : "Cannot connect to Agent endpoint"

```bash
# 1. V√©rifier que l'endpoint existe
databricks serving-endpoints list

# 2. V√©rifier l'URL dans la config
databricks apps get sncf-travel-assistant-dev --output json | grep AGENT_ENDPOINT_URL

# 3. V√©rifier les permissions du token
databricks current-user me
```

### Probl√®me : "Bundle validation failed"

```bash
# 1. V√©rifier la syntaxe YAML
# Utiliser un validateur YAML en ligne ou :
python -c "import yaml; yaml.safe_load(open('databricks.yml'))"

# 2. V√©rifier les r√©f√©rences de ressources
# 3. V√©rifier que les variables sont d√©finies
```

### Probl√®me : "Frontend returns 404"

Le frontend Next.js doit √™tre build√© :

```bash
cd frontend
npm install
npm run build

# V√©rifier que le dossier 'out' ou '.next' est cr√©√©
ls -la

# Red√©ployer
cd ..
databricks bundle deploy -t dev
```

## üìä Monitoring en Production

### Alertes Recommand√©es

Configurez des alertes pour :
- App status != running
- Taux d'erreur > 5%
- Temps de r√©ponse > 5s
- Utilisation m√©moire > 80%

### Logs Centralis√©s

Exportez les logs vers un syst√®me de logging centralis√© :
- AWS CloudWatch
- Azure Monitor
- Splunk
- Datadog

### Backup

Sauvegardez r√©guli√®rement :
- Code source (via Git)
- Configuration (databricks.yml, app.yaml)
- Secrets (documentation s√©curis√©e)
- Donn√©es du Unity Catalog

## üîê Best Practices de S√©curit√©

1. **Jamais de secrets en clair** dans le code ou les configs
2. **Service Principal** pour staging et prod (pas de tokens personnels)
3. **Rotation r√©guli√®re des tokens** (tous les 90 jours)
4. **Principe du moindre privil√®ge** pour les permissions
5. **Audit logs** : Activez les audit logs Databricks
6. **Network isolation** : Utilisez des Private Links si disponible

## üìû Support

En cas de probl√®me :

1. **Documentation Databricks** : https://docs.databricks.com/
2. **Community Forums** : https://community.databricks.com/
3. **Support Ticket** : Via votre workspace Databricks
4. **√âquipe interne** : Contactez votre √©quipe d'infrastructure

## üìö Ressources Suppl√©mentaires

- [Databricks Apps Quickstart](https://docs.databricks.com/en/dev-tools/databricks-apps/quickstart.html)
- [Asset Bundles Reference](https://docs.databricks.com/en/dev-tools/bundles/reference.html)
- [Model Serving Documentation](https://docs.databricks.com/en/machine-learning/model-serving/index.html)
- [Unity Catalog](https://docs.databricks.com/en/data-governance/unity-catalog/index.html)
