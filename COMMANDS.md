# Commandes CLI - SNCF Travel Assistant

Guide rapide des commandes CLI pour gÃ©rer l'application Databricks.

## ğŸš€ Databricks CLI - Installation et Configuration

### Installation

```bash
# Via pip
pip install databricks-cli

# Via Homebrew (macOS)
brew tap databricks/tap
brew install databricks

# Mise Ã  jour
pip install --upgrade databricks-cli
```

### Configuration

```bash
# Configuration interactive avec token
databricks configure --token

# Configuration avec des profils multiples
databricks configure --token --profile dev
databricks configure --token --profile prod

# Utiliser un profil spÃ©cifique
databricks --profile prod workspace list /
```

### VÃ©rification

```bash
# Version du CLI
databricks --version

# Profil actif
databricks auth profiles

# Tester la connexion
databricks current-user me
```

## ğŸ“¦ Databricks Asset Bundles

### Validation

```bash
# Valider la configuration (environnement dev par dÃ©faut)
databricks bundle validate

# Valider un environnement spÃ©cifique
databricks bundle validate -t dev
databricks bundle validate -t staging
databricks bundle validate -t prod

# Mode verbose pour plus de dÃ©tails
databricks bundle validate -t dev -v

# Afficher la configuration rÃ©solue (aprÃ¨s substitution des variables)
databricks bundle validate -t dev --output json
```

### DÃ©ploiement

```bash
# DÃ©ployer sur dev
databricks bundle deploy -t dev

# DÃ©ployer sur staging
databricks bundle deploy -t staging

# DÃ©ployer sur prod (avec confirmation)
databricks bundle deploy -t prod

# DÃ©ployer avec un profil spÃ©cifique
databricks bundle deploy -t prod --profile production

# Forcer le redÃ©ploiement (mÃªme si rien n'a changÃ©)
databricks bundle deploy -t dev --force
```

### Destruction

```bash
# Supprimer toutes les ressources d'un bundle
databricks bundle destroy -t dev

# Avec confirmation automatique (attention !)
databricks bundle destroy -t dev --auto-approve
```

## ğŸ“± Gestion des Apps

### Lister et Consulter

```bash
# Lister toutes les apps
databricks apps list

# Lister avec format JSON
databricks apps list --output json

# DÃ©tails d'une app spÃ©cifique
databricks apps get sncf-travel-assistant-dev

# DÃ©tails en JSON
databricks apps get sncf-travel-assistant-dev --output json

# Extraire l'URL de l'app
databricks apps get sncf-travel-assistant-dev --output json | jq -r '.url'
```

### ContrÃ´le de l'App

```bash
# DÃ©marrer une app arrÃªtÃ©e
databricks apps start sncf-travel-assistant-dev

# ArrÃªter une app
databricks apps stop sncf-travel-assistant-dev

# RedÃ©marrer une app
databricks apps restart sncf-travel-assistant-dev

# Supprimer une app
databricks apps delete sncf-travel-assistant-dev

# Supprimer sans confirmation
databricks apps delete sncf-travel-assistant-dev --yes
```

### Logs

```bash
# Afficher les logs
databricks apps logs sncf-travel-assistant-dev

# Logs en temps rÃ©el (follow)
databricks apps logs sncf-travel-assistant-dev --follow

# Logs des derniÃ¨res heures/jours
databricks apps logs sncf-travel-assistant-dev --since 1h
databricks apps logs sncf-travel-assistant-dev --since 24h
databricks apps logs sncf-travel-assistant-dev --since 7d

# Limiter le nombre de lignes
databricks apps logs sncf-travel-assistant-dev --tail 100

# Sauvegarder les logs
databricks apps logs sncf-travel-assistant-dev > app.log
databricks apps logs sncf-travel-assistant-dev --since 24h > app-24h.log
```

### MÃ©triques

```bash
# Obtenir les mÃ©triques de l'app
databricks apps get-metrics sncf-travel-assistant-dev

# MÃ©triques en JSON
databricks apps get-metrics sncf-travel-assistant-dev --output json
```

## ğŸ” Gestion des Secrets

### Scopes

```bash
# Lister tous les scopes
databricks secrets list-scopes

# CrÃ©er un nouveau scope
databricks secrets create-scope sncf-travel-app

# Supprimer un scope (et tous ses secrets)
databricks secrets delete-scope sncf-travel-app
```

### Secrets

```bash
# Lister les secrets d'un scope (noms seulement)
databricks secrets list-secrets sncf-travel-app

# Ajouter/Mettre Ã  jour un secret (ouvre un Ã©diteur)
databricks secrets put-secret sncf-travel-app databricks-token

# Ajouter un secret depuis stdin
echo "my-secret-value" | databricks secrets put-secret sncf-travel-app my-secret --binary-file /dev/stdin

# Supprimer un secret
databricks secrets delete-secret sncf-travel-app databricks-token

# Permissions sur un scope
databricks secrets list-acls sncf-travel-app
databricks secrets put-acl sncf-travel-app --principal users --permission READ
```

## ğŸ¤– Model Serving Endpoints

### Lister et Consulter

```bash
# Lister tous les endpoints
databricks serving-endpoints list

# DÃ©tails d'un endpoint
databricks serving-endpoints get sncf-travel-agent-dev

# En JSON
databricks serving-endpoints get sncf-travel-agent-dev --output json
```

### Gestion

```bash
# CrÃ©er un endpoint (via bundle ou manuellement)
databricks serving-endpoints create --json-file endpoint-config.json

# Mettre Ã  jour un endpoint
databricks serving-endpoints update sncf-travel-agent-dev --json-file updated-config.json

# Supprimer un endpoint
databricks serving-endpoints delete sncf-travel-agent-dev
```

### Logs et MÃ©triques

```bash
# Logs du endpoint
databricks serving-endpoints logs sncf-travel-agent-dev

# MÃ©triques
databricks serving-endpoints metrics sncf-travel-agent-dev
```

### Test

```bash
# Tester un endpoint (requÃªte POST)
databricks serving-endpoints query sncf-travel-agent-dev \
  --json '{
    "messages": [
      {
        "role": "user",
        "content": "Quel est mon prochain train ?"
      }
    ]
  }'
```

## ğŸ’¼ Workspace

### Navigation

```bash
# Lister le contenu d'un rÃ©pertoire
databricks workspace list /

# Lister rÃ©cursivement
databricks workspace list -l /Users

# CrÃ©er un rÃ©pertoire
databricks workspace mkdirs /Users/myuser/my-project
```

### Upload/Download

```bash
# Upload un fichier
databricks workspace import myfile.py /Users/myuser/myfile.py

# Upload un dossier rÃ©cursivement
databricks workspace import-dir ./local-folder /Users/myuser/remote-folder

# Download un fichier
databricks workspace export /Users/myuser/myfile.py myfile.py

# Download un dossier
databricks workspace export-dir /Users/myuser/remote-folder ./local-folder
```

## ğŸ“Š Jobs (si configurÃ©s dans le bundle)

### Lister et Consulter

```bash
# Lister tous les jobs
databricks jobs list

# DÃ©tails d'un job
databricks jobs get --job-id 123456

# Lister les runs d'un job
databricks jobs runs list --job-id 123456
```

### ExÃ©cution

```bash
# Lancer un job manuellement
databricks jobs run-now --job-id 123456

# Lancer avec des paramÃ¨tres
databricks jobs run-now --job-id 123456 --json '{
  "notebook_params": {
    "param1": "value1"
  }
}'

# Voir le statut d'un run
databricks jobs runs get --run-id 789012

# Annuler un run
databricks jobs runs cancel --run-id 789012
```

## ğŸ§ª Test des Endpoints API

### Health Check

```bash
# Test de santÃ©
curl https://your-app-url/health

# Avec formatage JSON
curl -s https://your-app-url/health | jq
```

### Chatbot

```bash
# Envoyer un message
curl -X POST https://your-app-url/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Quel est mon prochain train ?",
    "user_id": "test-user",
    "conversation_id": "test-conv-123"
  }' | jq

# Test avec httpie (plus lisible)
http POST https://your-app-url/api/chat \
  message="Quel est mon prochain train ?" \
  user_id="test-user"
```

### Admin Endpoints

```bash
# KPIs
curl -s https://your-app-url/api/admin/kpis | jq

# Charts
curl -s https://your-app-url/api/admin/charts | jq

# Analytics
curl -s https://your-app-url/api/analytics | jq

# Trips
curl -s https://your-app-url/api/trips | jq
```

### Test de Charge

```bash
# Test simple avec Apache Bench
ab -n 1000 -c 10 https://your-app-url/health

# Test avec wrk
wrk -t4 -c100 -d30s https://your-app-url/health

# Test POST avec wrk
wrk -t4 -c100 -d30s -s post.lua https://your-app-url/api/chat

# Contenu de post.lua :
# wrk.method = "POST"
# wrk.body   = '{"message":"test","user_id":"test"}'
# wrk.headers["Content-Type"] = "application/json"
```

## ğŸ” Debugging

### Logs DÃ©taillÃ©s

```bash
# Backend logs avec contexte
databricks apps logs sncf-travel-assistant-dev --follow | grep ERROR

# Filtrer par timestamp
databricks apps logs sncf-travel-assistant-dev --since 1h | grep "2026-01-21"

# Compter les erreurs
databricks apps logs sncf-travel-assistant-dev --since 24h | grep -c ERROR
```

### Inspection de l'Ã‰tat

```bash
# Ã‰tat complet de l'app en JSON
databricks apps get sncf-travel-assistant-dev --output json | jq

# VÃ©rifier les variables d'environnement
databricks apps get sncf-travel-assistant-dev --output json | jq '.config.env'

# VÃ©rifier la commande de dÃ©marrage
databricks apps get sncf-travel-assistant-dev --output json | jq '.config.command'

# URL de l'app
databricks apps get sncf-travel-assistant-dev --output json | jq -r '.url'
```

### Validation des Resources

```bash
# VÃ©rifier que les ressources existent
databricks serving-endpoints get sncf-travel-agent-dev
databricks secrets list-secrets sncf-travel-app

# Tester la connectivitÃ©
curl -v https://your-workspace/serving-endpoints/sncf-travel-agent-dev/invocations
```

## ğŸ”„ Workflow Complet de DÃ©ploiement

### DÃ©veloppement Local â†’ Dev

```bash
# 1. DÃ©velopper et tester localement
cd backend
python server.py

# 2. Valider le bundle
databricks bundle validate -t dev

# 3. DÃ©ployer
databricks bundle deploy -t dev

# 4. VÃ©rifier
databricks apps get sncf-travel-assistant-dev
databricks apps logs sncf-travel-assistant-dev --tail 50

# 5. Tester
curl https://your-app-url/health
```

### Dev â†’ Staging

```bash
# 1. Valider sur staging
databricks bundle validate -t staging

# 2. DÃ©ployer
databricks bundle deploy -t staging

# 3. Tests automatisÃ©s (Ã  implÃ©menter)
./scripts/test-staging.sh

# 4. Smoke test manuel
curl https://staging-app-url/health
curl https://staging-app-url/api/admin/kpis
```

### Staging â†’ Production

```bash
# 1. Review final
databricks bundle validate -t prod

# 2. DÃ©ploiement avec profil prod
databricks bundle deploy -t prod --profile production

# 3. VÃ©rification
databricks apps get sncf-travel-assistant --profile production

# 4. Monitoring
databricks apps logs sncf-travel-assistant --follow --profile production

# 5. Health check
curl https://prod-app-url/health
```

## ğŸ“ Scripts Utiles

### Monitoring Continu

```bash
#!/bin/bash
# monitor-app.sh - Surveiller la santÃ© de l'app

APP_NAME="sncf-travel-assistant-dev"
URL=$(databricks apps get $APP_NAME --output json | jq -r '.url')

while true; do
  STATUS=$(curl -s $URL/health | jq -r '.status')
  echo "$(date) - Status: $STATUS"
  
  if [ "$STATUS" != "healthy" ]; then
    echo "âš ï¸  App is unhealthy!"
    databricks apps logs $APP_NAME --tail 20
  fi
  
  sleep 60
done
```

### Rotation des Logs

```bash
#!/bin/bash
# save-logs.sh - Sauvegarder les logs quotidiennement

APP_NAME="sncf-travel-assistant-dev"
DATE=$(date +%Y-%m-%d)
LOG_FILE="logs/app-$DATE.log"

databricks apps logs $APP_NAME --since 24h > $LOG_FILE
gzip $LOG_FILE
```

### DÃ©ploiement AutomatisÃ©

```bash
#!/bin/bash
# deploy.sh - Script de dÃ©ploiement

set -e

TARGET=${1:-dev}

echo "ğŸš€ DÃ©ploiement sur $TARGET..."

# Validation
echo "ğŸ“‹ Validation..."
databricks bundle validate -t $TARGET

# DÃ©ploiement
echo "ğŸ”§ DÃ©ploiement..."
databricks bundle deploy -t $TARGET

# VÃ©rification
echo "âœ… VÃ©rification..."
APP_NAME=$(databricks bundle validate -t $TARGET --output json | jq -r '.resources.apps[].name')
databricks apps get $APP_NAME

# Health check
echo "ğŸ¥ Health check..."
sleep 10
URL=$(databricks apps get $APP_NAME --output json | jq -r '.url')
curl -f $URL/health || exit 1

echo "âœ¨ DÃ©ploiement rÃ©ussi!"
```

## ğŸ“š Ressources

- [Databricks CLI Reference](https://docs.databricks.com/en/dev-tools/cli/index.html)
- [Bundle CLI Commands](https://docs.databricks.com/en/dev-tools/bundles/cli-commands.html)
- [Apps CLI Commands](https://docs.databricks.com/en/dev-tools/databricks-apps/cli.html)
